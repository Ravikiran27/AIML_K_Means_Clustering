{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa67f6da",
   "metadata": {},
   "source": [
    "# Multi-Pollutant Profile Grouping of Air Quality Data Using K-Means Clustering\n",
    "\n",
    "## Comprehensive Analysis Covering All Presenter Sections\n",
    "\n",
    "This notebook demonstrates manual K-means clustering implementation on air quality data without using sklearn. We'll analyze pollution patterns across different scales - from urban to country levels - using various pollutant combinations.\n",
    "\n",
    "### Presentation Structure:\n",
    "1. **Presenter 1**: Simple 2D Clustering (PM2.5 and PM10)\n",
    "2. **Presenter 2**: Country-Level AQI Clustering  \n",
    "3. **Presenter 3**: City-Level AQI Clustering\n",
    "4. **Presenter 4**: Two-Pollutant City Clustering (PM2.5 and NO2)\n",
    "5. **Presenter 5**: Multi-Feature Three-Pollutant Clustering\n",
    "6. **Results Comparison and Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d42ad80",
   "metadata": {},
   "source": [
    "## Section 1: Data Preparation and Imports\n",
    "\n",
    "First, let's import the necessary libraries and prepare our dataset. We'll implement everything manually without using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129d442",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'typing_extensions'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Manual K-Means Implementation\n",
    "class ManualKMeans:\n",
    "    def __init__(self, k=2, max_iters=100, random_state=42):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "        random.seed(random_state)\n",
    "        \n",
    "    def euclidean_distance(self, point1, point2):\n",
    "        \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
    "        if isinstance(point1, (int, float)) and isinstance(point2, (int, float)):\n",
    "            return abs(point1 - point2)\n",
    "        \n",
    "        distance = 0\n",
    "        for i in range(len(point1)):\n",
    "            distance += (point1[i] - point2[i]) ** 2\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    def initialize_centroids(self, data):\n",
    "        \"\"\"Initialize centroids randomly\"\"\"\n",
    "        if not data:\n",
    "            return []\n",
    "        \n",
    "        # Check if data is 1D or multi-dimensional\n",
    "        if isinstance(data[0], (int, float)):\n",
    "            # 1D data\n",
    "            min_val, max_val = min(data), max(data)\n",
    "            return [random.uniform(min_val, max_val) for _ in range(self.k)]\n",
    "        else:\n",
    "            # Multi-dimensional data\n",
    "            n_features = len(data[0])\n",
    "            centroids = []\n",
    "            for _ in range(self.k):\n",
    "                centroid = []\n",
    "                for j in range(n_features):\n",
    "                    feature_values = [point[j] for point in data]\n",
    "                    min_val, max_val = min(feature_values), max(feature_values)\n",
    "                    centroid.append(random.uniform(min_val, max_val))\n",
    "                centroids.append(centroid)\n",
    "            return centroids\n",
    "    \n",
    "    def assign_clusters(self, data, centroids):\n",
    "        \"\"\"Assign each point to the nearest centroid\"\"\"\n",
    "        clusters = [[] for _ in range(self.k)]\n",
    "        cluster_assignments = []\n",
    "        \n",
    "        for point in data:\n",
    "            distances = [self.euclidean_distance(point, centroid) for centroid in centroids]\n",
    "            closest_cluster = distances.index(min(distances))\n",
    "            clusters[closest_cluster].append(point)\n",
    "            cluster_assignments.append(closest_cluster)\n",
    "        \n",
    "        return clusters, cluster_assignments\n",
    "    \n",
    "    def update_centroids(self, clusters):\n",
    "        \"\"\"Update centroids based on current clusters\"\"\"\n",
    "        new_centroids = []\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            if not cluster:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(cluster[0], (int, float)):\n",
    "                # 1D data\n",
    "                centroid = sum(cluster) / len(cluster)\n",
    "            else:\n",
    "                # Multi-dimensional data\n",
    "                n_features = len(cluster[0])\n",
    "                centroid = []\n",
    "                for j in range(n_features):\n",
    "                    feature_sum = sum(point[j] for point in cluster)\n",
    "                    centroid.append(feature_sum / len(cluster))\n",
    "            \n",
    "            new_centroids.append(centroid)\n",
    "        \n",
    "        return new_centroids\n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"Fit K-means to the data\"\"\"\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "        self.history = [self.centroids.copy()]\n",
    "        \n",
    "        for iteration in range(self.max_iters):\n",
    "            clusters, assignments = self.assign_clusters(data, self.centroids)\n",
    "            new_centroids = self.update_centroids(clusters)\n",
    "            \n",
    "            # Remove None centroids (empty clusters)\n",
    "            new_centroids = [c for c in new_centroids if c is not None]\n",
    "            \n",
    "            # Check for convergence\n",
    "            if len(new_centroids) == len(self.centroids):\n",
    "                converged = True\n",
    "                for i, (old, new) in enumerate(zip(self.centroids, new_centroids)):\n",
    "                    if isinstance(old, (int, float)):\n",
    "                        if abs(old - new) > 1e-6:\n",
    "                            converged = False\n",
    "                            break\n",
    "                    else:\n",
    "                        if any(abs(o - n) > 1e-6 for o, n in zip(old, new)):\n",
    "                            converged = False\n",
    "                            break\n",
    "                \n",
    "                if converged:\n",
    "                    print(f\"Converged after {iteration + 1} iterations\")\n",
    "                    break\n",
    "            \n",
    "            self.centroids = new_centroids\n",
    "            self.history.append(self.centroids.copy())\n",
    "        \n",
    "        self.final_clusters, self.cluster_assignments = self.assign_clusters(data, self.centroids)\n",
    "        return self\n",
    "\n",
    "# Helper functions\n",
    "def load_air_quality_data():\n",
    "    \"\"\"Load the air quality dataset\"\"\"\n",
    "    data = []\n",
    "    with open('s:\\\\AIML\\\\global_air_quality_data_10000.csv', 'r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_city_averages(data, cities, pollutants):\n",
    "    \"\"\"Calculate average pollutant values for specified cities\"\"\"\n",
    "    city_data = defaultdict(list)\n",
    "    \n",
    "    for record in data:\n",
    "        city = record['City']\n",
    "        if city in cities:\n",
    "            pollutant_values = {}\n",
    "            for pollutant in pollutants:\n",
    "                try:\n",
    "                    value = float(record[pollutant])\n",
    "                    pollutant_values[pollutant] = value\n",
    "                except (ValueError, KeyError):\n",
    "                    continue\n",
    "            if len(pollutant_values) == len(pollutants):\n",
    "                city_data[city].append(pollutant_values)\n",
    "    \n",
    "    # Calculate averages\n",
    "    averages = {}\n",
    "    for city in cities:\n",
    "        if city in city_data and city_data[city]:\n",
    "            avg_values = []\n",
    "            for pollutant in pollutants:\n",
    "                values = [record[pollutant] for record in city_data[city]]\n",
    "                if values:\n",
    "                    avg_values.append(sum(values) / len(values))\n",
    "                else:\n",
    "                    avg_values.append(0)\n",
    "            averages[city] = avg_values\n",
    "    \n",
    "    return averages\n",
    "\n",
    "def calculate_aqi_simple(pm25, pm10, no2):\n",
    "    \"\"\"Simplified AQI calculation based on major pollutants\"\"\"\n",
    "    pm25_norm = min(pm25 / 35.0, 1.0) * 100\n",
    "    pm10_norm = min(pm10 / 50.0, 1.0) * 100\n",
    "    no2_norm = min(no2 / 40.0, 1.0) * 100\n",
    "    return max(pm25_norm, pm10_norm, no2_norm)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading air quality dataset...\")\n",
    "air_quality_data = load_air_quality_data()\n",
    "print(f\"Loaded {len(air_quality_data)} records\")\n",
    "\n",
    "# Sample first few records to understand the structure\n",
    "print(\"\\nFirst 3 records:\")\n",
    "for i, record in enumerate(air_quality_data[:3]):\n",
    "    print(f\"Record {i+1}: {record}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfa9e9",
   "metadata": {},
   "source": [
    "## Section 2: Presenter 1 - Simple 2D Clustering (PM2.5 and PM10)\n",
    "\n",
    "**Topic**: Clustering cities using two pollutants: PM2.5 and PM10  \n",
    "**Dataset Focus**: Sample of 10 cities with average PM2.5 and PM10 values  \n",
    "**Method**: Manual K-Means clustering with K=2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presenter 1: Simple 2D Clustering with PM2.5 and PM10\n",
    "\n",
    "def get_city_averages(data, cities, pollutants):\n",
    "    \"\"\"Calculate average pollutant values for specified cities\"\"\"\n",
    "    city_data = defaultdict(list)\n",
    "    \n",
    "    for record in data:\n",
    "        city = record['City']\n",
    "        if city in cities:\n",
    "            for pollutant in pollutants:\n",
    "                try:\n",
    "                    value = float(record[pollutant])\n",
    "                    city_data[city].append({pollutant: value})\n",
    "                except (ValueError, KeyError):\n",
    "                    continue\n",
    "    \n",
    "    # Calculate averages\n",
    "    averages = {}\n",
    "    for city in cities:\n",
    "        if city in city_data:\n",
    "            city_records = city_data[city]\n",
    "            avg_values = []\n",
    "            for pollutant in pollutants:\n",
    "                values = []\n",
    "                for record_dict in city_records:\n",
    "                    if pollutant in record_dict:\n",
    "                        values.append(record_dict[pollutant])\n",
    "                \n",
    "                if values:\n",
    "                    avg_values.append(sum(values) / len(values))\n",
    "                else:\n",
    "                    avg_values.append(0)\n",
    "            \n",
    "            averages[city] = avg_values\n",
    "    \n",
    "    return averages\n",
    "\n",
    "# Select 10 cities for analysis\n",
    "selected_cities = ['Bangkok', 'Istanbul', 'Mumbai', 'Paris', 'Tokyo', \n",
    "                  'New York', 'London', 'Cairo', 'Mexico City', 'Seoul']\n",
    "\n",
    "# Get average PM2.5 and PM10 values for these cities\n",
    "pollutants = ['PM2.5', 'PM10']\n",
    "city_averages = get_city_averages(air_quality_data, selected_cities, pollutants)\n",
    "\n",
    "print(\"Presenter 1: City averages for PM2.5 and PM10\")\n",
    "print(\"=\" * 50)\n",
    "for city, values in city_averages.items():\n",
    "    print(f\"{city:15}: PM2.5={values[0]:6.2f}, PM10={values[1]:6.2f}\")\n",
    "\n",
    "# Prepare data for clustering\n",
    "clustering_data = list(city_averages.values())\n",
    "city_names = list(city_averages.keys())\n",
    "\n",
    "print(f\"\\nClustering data shape: {len(clustering_data)} cities × {len(pollutants)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1aeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering with K=2\n",
    "kmeans_p1 = ManualKMeans(k=2, random_state=42)\n",
    "kmeans_p1.fit(clustering_data)\n",
    "\n",
    "print(\"\\nPresenter 1: K-Means Clustering Results (K=2)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display final centroids\n",
    "print(\"Final Centroids:\")\n",
    "for i, centroid in enumerate(kmeans_p1.centroids):\n",
    "    print(f\"Cluster {i+1}: PM2.5={centroid[0]:6.2f}, PM10={centroid[1]:6.2f}\")\n",
    "\n",
    "print(\"\\nCluster Assignments:\")\n",
    "for city, cluster_id in zip(city_names, kmeans_p1.cluster_assignments):\n",
    "    values = city_averages[city]\n",
    "    print(f\"{city:15}: Cluster {cluster_id+1} (PM2.5={values[0]:6.2f}, PM10={values[1]:6.2f})\")\n",
    "\n",
    "# Create detailed visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Scatter plot with clusters\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "cluster_names = ['Higher Pollution Group', 'Lower Pollution Group']\n",
    "\n",
    "for i in range(kmeans_p1.k):\n",
    "    cluster_cities = [city for city, cluster in zip(city_names, kmeans_p1.cluster_assignments) if cluster == i]\n",
    "    cluster_data = [city_averages[city] for city in cluster_cities]\n",
    "    \n",
    "    if cluster_data:\n",
    "        pm25_values = [point[0] for point in cluster_data]\n",
    "        pm10_values = [point[1] for point in cluster_data]\n",
    "        ax1.scatter(pm25_values, pm10_values, c=colors[i], label=f'Cluster {i+1}: {cluster_names[i]}', \n",
    "                   s=120, alpha=0.8, edgecolors='black', linewidth=1)\n",
    "        \n",
    "        # Add city labels\n",
    "        for city, pm25, pm10 in zip(cluster_cities, pm25_values, pm10_values):\n",
    "            ax1.annotate(city, (pm25, pm10), xytext=(5, 5), textcoords='offset points', \n",
    "                        fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot centroids\n",
    "for i, centroid in enumerate(kmeans_p1.centroids):\n",
    "    ax1.scatter(centroid[0], centroid[1], c='black', marker='X', s=300, \n",
    "                edgecolors=colors[i], linewidth=3, label=f'Centroid {i+1}')\n",
    "\n",
    "ax1.set_xlabel('PM2.5 (μg/m³)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('PM10 (μg/m³)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Presenter 1: City Clustering by PM2.5 and PM10 (K=2)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bar chart showing cluster statistics\n",
    "cluster_stats = {}\n",
    "for i in range(kmeans_p1.k):\n",
    "    cluster_cities = [city for city, cluster in zip(city_names, kmeans_p1.cluster_assignments) if cluster == i]\n",
    "    cluster_data = [city_averages[city] for city in cluster_cities]\n",
    "    \n",
    "    if cluster_data:\n",
    "        avg_pm25 = sum(point[0] for point in cluster_data) / len(cluster_data)\n",
    "        avg_pm10 = sum(point[1] for point in cluster_data) / len(cluster_data)\n",
    "        cluster_stats[f'Cluster {i+1}'] = {'PM2.5': avg_pm25, 'PM10': avg_pm10, 'Cities': len(cluster_data)}\n",
    "\n",
    "x_pos = np.arange(len(cluster_stats))\n",
    "pm25_values = [stats['PM2.5'] for stats in cluster_stats.values()]\n",
    "pm10_values = [stats['PM10'] for stats in cluster_stats.values()]\n",
    "\n",
    "width = 0.35\n",
    "bars1 = ax2.bar(x_pos - width/2, pm25_values, width, label='PM2.5', color=colors[0], alpha=0.8)\n",
    "bars2 = ax2.bar(x_pos + width/2, pm10_values, width, label='PM10', color=colors[1], alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Clusters', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average Concentration (μg/m³)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Average Pollutant Levels by Cluster', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(cluster_stats.keys())\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.annotate(f'{height:.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Conclusion from Clustered Graph:\")\n",
    "print(\"The visualization reveals two distinct groups—one with higher pollution and one cleaner cluster—\")\n",
    "print(\"demonstrating a clear distinction even with just two features. This sets the foundation\")\n",
    "print(\"for more complex multi-feature clustering analyses.\")\n",
    "\n",
    "print(f\"\\nCluster Statistics:\")\n",
    "for cluster_name, stats in cluster_stats.items():\n",
    "    print(f\"  {cluster_name}: {stats['Cities']} cities, Avg PM2.5={stats['PM2.5']:.2f}, Avg PM10={stats['PM10']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721da86",
   "metadata": {},
   "source": [
    "## Section 3: Presenter 2 - Country-Level AQI Clustering\n",
    "\n",
    "**Topic**: Grouping countries by average AQI into Low, Medium, and High pollution clusters  \n",
    "**Dataset Focus**: 6 countries' average AQI extracted from the dataset  \n",
    "**Method**: 1D K-Means clustering with K=3 on AQI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presenter 2: Country-Level AQI Clustering\n",
    "\n",
    "def calculate_aqi_simple(pm25, pm10, no2):\n",
    "    \"\"\"\n",
    "    Simplified AQI calculation based on major pollutants\n",
    "    This is a simplified version for demonstration purposes\n",
    "    \"\"\"\n",
    "    # Normalize values and combine (simplified approach)\n",
    "    pm25_norm = min(pm25 / 35.0, 1.0) * 100  # WHO guideline: 15 μg/m³ annual, 35 daily\n",
    "    pm10_norm = min(pm10 / 50.0, 1.0) * 100  # WHO guideline: 45 μg/m³ annual, 50 daily\n",
    "    no2_norm = min(no2 / 40.0, 1.0) * 100    # WHO guideline: 40 μg/m³ annual\n",
    "    \n",
    "    # Take the maximum as the limiting factor\n",
    "    aqi = max(pm25_norm, pm10_norm, no2_norm)\n",
    "    return aqi\n",
    "\n",
    "def get_country_aqi_averages(data, countries):\n",
    "    \"\"\"Calculate average AQI for specified countries\"\"\"\n",
    "    country_data = defaultdict(list)\n",
    "    \n",
    "    for record in data:\n",
    "        country = record['Country']\n",
    "        if country in countries:\n",
    "            try:\n",
    "                pm25 = float(record['PM2.5'])\n",
    "                pm10 = float(record['PM10'])\n",
    "                no2 = float(record['NO2'])\n",
    "                \n",
    "                aqi = calculate_aqi_simple(pm25, pm10, no2)\n",
    "                country_data[country].append(aqi)\n",
    "            except (ValueError, KeyError):\n",
    "                continue\n",
    "    \n",
    "    # Calculate averages\n",
    "    averages = {}\n",
    "    for country in countries:\n",
    "        if country in country_data and country_data[country]:\n",
    "            averages[country] = sum(country_data[country]) / len(country_data[country])\n",
    "    \n",
    "    return averages\n",
    "\n",
    "# Select 6 countries for analysis\n",
    "selected_countries = ['Thailand', 'Turkey', 'Brazil', 'India', 'France', 'USA']\n",
    "\n",
    "# Get average AQI values for these countries\n",
    "country_aqi = get_country_aqi_averages(air_quality_data, selected_countries)\n",
    "\n",
    "print(\"Presenter 2: Country Average AQI Values\")\n",
    "print(\"=\" * 40)\n",
    "for country, aqi in sorted(country_aqi.items(), key=lambda x: x[1]):\n",
    "    print(f\"{country:12}: AQI = {aqi:6.2f}\")\n",
    "\n",
    "# Prepare data for clustering (1D)\n",
    "aqi_values = list(country_aqi.values())\n",
    "country_names_p2 = list(country_aqi.keys())\n",
    "\n",
    "print(f\"\\nClustering data: {len(aqi_values)} countries with AQI values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering with K=3 for country AQI\n",
    "kmeans_p2 = ManualKMeans(k=3, random_state=42)\n",
    "kmeans_p2.fit(aqi_values)\n",
    "\n",
    "print(\"\\nPresenter 2: K-Means Clustering Results (K=3)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display final centroids\n",
    "print(\"Final Centroids (AQI levels):\")\n",
    "centroid_labels = ['Low Pollution', 'Medium Pollution', 'High Pollution']\n",
    "sorted_centroids = sorted(enumerate(kmeans_p2.centroids), key=lambda x: x[1])\n",
    "\n",
    "for i, (orig_idx, centroid) in enumerate(sorted_centroids):\n",
    "    print(f\"Cluster {orig_idx+1} ({centroid_labels[i]}): AQI = {centroid:6.2f}\")\n",
    "\n",
    "print(\"\\nCountry Cluster Assignments:\")\n",
    "for country, cluster_id, aqi in zip(country_names_p2, kmeans_p2.cluster_assignments, aqi_values):\n",
    "    print(f\"{country:12}: Cluster {cluster_id+1} - AQI = {aqi:6.2f}\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: 1D scatter plot along AQI axis\n",
    "colors = ['#2ECC71', '#F39C12', '#E74C3C']  # Green, Orange, Red\n",
    "pollution_levels = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Group countries by cluster\n",
    "cluster_groups = {i: [] for i in range(kmeans_p2.k)}\n",
    "for country, cluster_id, aqi in zip(country_names_p2, kmeans_p2.cluster_assignments, aqi_values):\n",
    "    cluster_groups[cluster_id].append((country, aqi))\n",
    "\n",
    "y_offset = 0.1\n",
    "for i in range(kmeans_p2.k):\n",
    "    if cluster_groups[i]:\n",
    "        countries, aqis = zip(*cluster_groups[i])\n",
    "        y_positions = [i + random.uniform(-y_offset, y_offset) for _ in aqis]\n",
    "        ax1.scatter(aqis, y_positions, c=colors[i], label=f'Cluster {i+1}', s=150, alpha=0.8, edgecolors='black')\n",
    "        \n",
    "        # Add country labels\n",
    "        for country, aqi, y in zip(countries, aqis, y_positions):\n",
    "            ax1.annotate(country, (aqi, y), xytext=(5, 0), textcoords='offset points', \n",
    "                        fontsize=10, fontweight='bold', va='center')\n",
    "\n",
    "# Plot centroids\n",
    "for i, centroid in enumerate(kmeans_p2.centroids):\n",
    "    ax1.axvline(x=centroid, color=colors[i], linestyle='--', linewidth=3, alpha=0.7)\n",
    "    ax1.scatter(centroid, i, c='black', marker='X', s=300, \n",
    "                edgecolors=colors[i], linewidth=3, zorder=5)\n",
    "\n",
    "ax1.set_xlabel('Average AQI', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Cluster', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Presenter 2: Country Clustering by Average AQI (K=3)', fontsize=14, fontweight='bold')\n",
    "ax1.set_yticks(range(kmeans_p2.k))\n",
    "ax1.set_yticklabels([f'Cluster {i+1}' for i in range(kmeans_p2.k)])\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bar chart of AQI values by country\n",
    "countries_sorted = sorted(zip(country_names_p2, aqi_values, kmeans_p2.cluster_assignments), key=lambda x: x[1])\n",
    "countries, aqis_sorted, clusters = zip(*countries_sorted)\n",
    "\n",
    "bars = ax2.bar(range(len(countries)), aqis_sorted, \n",
    "               color=[colors[cluster] for cluster in clusters], alpha=0.8, edgecolor='black')\n",
    "ax2.set_xlabel('Countries', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average AQI', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('AQI Values by Country (Colored by Cluster)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(len(countries)))\n",
    "ax2.set_xticklabels(countries, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, aqi in zip(bars, aqis_sorted):\n",
    "    ax2.annotate(f'{aqi:.1f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: Pie chart showing cluster distribution\n",
    "cluster_counts = [len(cluster_groups[i]) for i in range(kmeans_p2.k)]\n",
    "cluster_labels_pie = [f'Cluster {i+1}\\n({pollution_levels[i]} Pollution)\\n{count} countries' \n",
    "                     for i, count in enumerate(cluster_counts)]\n",
    "\n",
    "wedges, texts, autotexts = ax3.pie(cluster_counts, labels=cluster_labels_pie, colors=colors, \n",
    "                                  autopct='%1.1f%%', startangle=90, textprops={'fontweight': 'bold'})\n",
    "ax3.set_title('Distribution of Countries by Pollution Level', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Centroid comparison\n",
    "centroid_values = [kmeans_p2.centroids[i] for i in range(kmeans_p2.k)]\n",
    "bars4 = ax4.bar(range(kmeans_p2.k), centroid_values, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_xlabel('Pollution Level', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Centroid AQI Value', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Cluster Centroids Comparison', fontsize=14, fontweight='bold')\n",
    "ax4.set_xticks(range(kmeans_p2.k))\n",
    "ax4.set_xticklabels([f'{pollution_levels[i]}\\nPollution' for i in range(kmeans_p2.k)])\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars4, centroid_values):\n",
    "    ax4.annotate(f'{value:.2f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Conclusion from Clustered Graph:\")\n",
    "print(\"Distinct partitions indicate national-level air quality differences. This clustering\")\n",
    "print(\"enables policymakers to focus resources on high-risk nations by identifying\")\n",
    "print(\"the pollution severity category.\")\n",
    "\n",
    "print(f\"\\nDetailed Cluster Analysis:\")\n",
    "for i in range(kmeans_p2.k):\n",
    "    if cluster_groups[i]:\n",
    "        print(f\"  🌍 {pollution_levels[i]} Pollution Cluster ({len(cluster_groups[i])} countries):\")\n",
    "        print(f\"     Centroid AQI: {kmeans_p2.centroids[i]:.2f}\")\n",
    "        print(f\"     Countries: {', '.join([country for country, _ in cluster_groups[i]])}\")\n",
    "        avg_aqi = sum(aqi for _, aqi in cluster_groups[i]) / len(cluster_groups[i])\n",
    "        print(f\"     Average AQI: {avg_aqi:.2f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd924a90",
   "metadata": {},
   "source": [
    "## Section 4: Presenter 3 - City-Level AQI Clustering\n",
    "\n",
    "**Topic**: Clustering 8 cities based on AQI alone  \n",
    "**Dataset Focus**: AQI values for 8 cities in the dataset  \n",
    "**Method**: K=3 clusters created using manual assignment and centroid updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2eb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presenter 3: City-Level AQI Clustering\n",
    "\n",
    "def get_city_aqi_averages(data, cities):\n",
    "    \"\"\"Calculate average AQI for specified cities\"\"\"\n",
    "    city_data = defaultdict(list)\n",
    "    \n",
    "    for record in data:\n",
    "        city = record['City']\n",
    "        if city in cities:\n",
    "            try:\n",
    "                pm25 = float(record['PM2.5'])\n",
    "                pm10 = float(record['PM10'])\n",
    "                no2 = float(record['NO2'])\n",
    "                \n",
    "                aqi = calculate_aqi_simple(pm25, pm10, no2)\n",
    "                city_data[city].append(aqi)\n",
    "            except (ValueError, KeyError):\n",
    "                continue\n",
    "    \n",
    "    # Calculate averages\n",
    "    averages = {}\n",
    "    for city in cities:\n",
    "        if city in city_data and city_data[city]:\n",
    "            averages[city] = sum(city_data[city]) / len(city_data[city])\n",
    "    \n",
    "    return averages\n",
    "\n",
    "# Select 8 cities for analysis\n",
    "selected_cities_p3 = ['Bangkok', 'Istanbul', 'Mumbai', 'Paris', 'Tokyo', 'New York', 'London', 'Cairo']\n",
    "\n",
    "# Get average AQI values for these cities\n",
    "city_aqi = get_city_aqi_averages(air_quality_data, selected_cities_p3)\n",
    "\n",
    "print(\"Presenter 3: City Average AQI Values\")\n",
    "print(\"=\" * 40)\n",
    "for city, aqi in sorted(city_aqi.items(), key=lambda x: x[1]):\n",
    "    print(f\"{city:15}: AQI = {aqi:6.2f}\")\n",
    "\n",
    "# Prepare data for clustering (1D)\n",
    "city_aqi_values = list(city_aqi.values())\n",
    "city_names_p3 = list(city_aqi.keys())\n",
    "\n",
    "print(f\"\\nClustering data: {len(city_aqi_values)} cities with AQI values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering with K=3 for city AQI\n",
    "kmeans_p3 = ManualKMeans(k=3, random_state=42)\n",
    "kmeans_p3.fit(city_aqi_values)\n",
    "\n",
    "print(\"\\nPresenter 3: K-Means Clustering Results (K=3)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display final centroids\n",
    "print(\"Final Centroids (AQI levels):\")\n",
    "centroid_labels = ['Low Pollution', 'Medium Pollution', 'High Pollution']\n",
    "sorted_centroids_p3 = sorted(enumerate(kmeans_p3.centroids), key=lambda x: x[1])\n",
    "\n",
    "for i, (orig_idx, centroid) in enumerate(sorted_centroids_p3):\n",
    "    print(f\"Cluster {orig_idx+1} ({centroid_labels[i]}): AQI = {centroid:6.2f}\")\n",
    "\n",
    "print(\"\\nCity Cluster Assignments (Textual Output):\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Group cities by cluster\n",
    "clusters_dict = defaultdict(list)\n",
    "for city, cluster_id, aqi in zip(city_names_p3, kmeans_p3.cluster_assignments, city_aqi_values):\n",
    "    clusters_dict[cluster_id].append((city, aqi))\n",
    "\n",
    "# Display each cluster\n",
    "for cluster_id in range(kmeans_p3.k):\n",
    "    centroid_aqi = kmeans_p3.centroids[cluster_id]\n",
    "    # Determine pollution level based on centroid value\n",
    "    if centroid_aqi < 50:\n",
    "        level = \"Low Pollution\"\n",
    "    elif centroid_aqi < 75:\n",
    "        level = \"Medium Pollution\" \n",
    "    else:\n",
    "        level = \"High Pollution\"\n",
    "    \n",
    "    print(f\"\\n🏙️  CLUSTER {cluster_id+1} ({level}):\")\n",
    "    print(f\"   Centroid AQI: {centroid_aqi:.2f}\")\n",
    "    print(\"   Cities in this cluster:\")\n",
    "    \n",
    "    for city, aqi in sorted(clusters_dict[cluster_id], key=lambda x: x[1]):\n",
    "        print(f\"   • {city:15}: AQI = {aqi:6.2f}\")\n",
    "\n",
    "print(\"\\n📊 Conclusion from Clustering:\")\n",
    "print(\"Clusters effectively group cities by similar pollution levels, enabling identification\")\n",
    "print(\"of local pollution discrepancies and facilitating targeted urban pollution management.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d33939",
   "metadata": {},
   "source": [
    "## Section 5: Presenter 4 - Two-Pollutant City Clustering (PM2.5 and NO2)\n",
    "\n",
    "**Topic**: Multi-feature clustering for 8 cities using PM2.5 and NO2  \n",
    "**Dataset Focus**: Average PM2.5 and NO2 for 8 cities in the dataset  \n",
    "**Method**: Manual K-Means with K=3 clusters, showing centroid movement iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffe12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presenter 4: Two-Pollutant City Clustering (PM2.5 and NO2)\n",
    "\n",
    "# Select 8 cities for analysis\n",
    "selected_cities_p4 = ['Bangkok', 'Istanbul', 'Mumbai', 'Paris', 'Tokyo', 'New York', 'London', 'Cairo']\n",
    "\n",
    "# Get average PM2.5 and NO2 values for these cities\n",
    "pollutants_p4 = ['PM2.5', 'NO2']\n",
    "city_averages_p4 = get_city_averages(air_quality_data, selected_cities_p4, pollutants_p4)\n",
    "\n",
    "print(\"Presenter 4: City averages for PM2.5 and NO2\")\n",
    "print(\"=\" * 50)\n",
    "for city, values in city_averages_p4.items():\n",
    "    print(f\"{city:15}: PM2.5={values[0]:6.2f}, NO2={values[1]:6.2f}\")\n",
    "\n",
    "# Prepare data for clustering\n",
    "clustering_data_p4 = list(city_averages_p4.values())\n",
    "city_names_p4 = list(city_averages_p4.keys())\n",
    "\n",
    "print(f\"\\nClustering data shape: {len(clustering_data_p4)} cities × {len(pollutants_p4)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering with K=3, showing iterations\n",
    "class IterativeKMeans(ManualKMeans):\n",
    "    def fit_with_iterations(self, data):\n",
    "        \"\"\"Fit K-means and return iteration history for visualization\"\"\"\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "        self.iteration_history = [self.centroids.copy()]\n",
    "        self.assignment_history = []\n",
    "        \n",
    "        for iteration in range(self.max_iters):\n",
    "            clusters, assignments = self.assign_clusters(data, self.centroids)\n",
    "            self.assignment_history.append(assignments.copy())\n",
    "            new_centroids = self.update_centroids(clusters)\n",
    "            \n",
    "            # Remove None centroids (empty clusters)\n",
    "            new_centroids = [c for c in new_centroids if c is not None]\n",
    "            \n",
    "            # Check for convergence\n",
    "            if len(new_centroids) == len(self.centroids):\n",
    "                converged = True\n",
    "                for old, new in zip(self.centroids, new_centroids):\n",
    "                    if any(abs(o - n) > 1e-6 for o, n in zip(old, new)):\n",
    "                        converged = False\n",
    "                        break\n",
    "                \n",
    "                if converged:\n",
    "                    print(f\"Converged after {iteration + 1} iterations\")\n",
    "                    break\n",
    "            \n",
    "            self.centroids = new_centroids\n",
    "            self.iteration_history.append(self.centroids.copy())\n",
    "        \n",
    "        self.final_clusters, self.cluster_assignments = self.assign_clusters(data, self.centroids)\n",
    "        return self\n",
    "\n",
    "# Perform clustering with iteration tracking\n",
    "kmeans_p4 = IterativeKMeans(k=3, random_state=42)\n",
    "kmeans_p4.fit_with_iterations(clustering_data_p4)\n",
    "\n",
    "print(\"\\nPresenter 4: K-Means Clustering Results (K=3)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display final centroids\n",
    "print(\"Final Centroids:\")\n",
    "for i, centroid in enumerate(kmeans_p4.centroids):\n",
    "    print(f\"Cluster {i+1}: PM2.5={centroid[0]:6.2f}, NO2={centroid[1]:6.2f}\")\n",
    "\n",
    "print(\"\\nCluster Assignments:\")\n",
    "for city, cluster_id in zip(city_names_p4, kmeans_p4.cluster_assignments):\n",
    "    values = city_averages_p4[city]\n",
    "    print(f\"{city:15}: Cluster {cluster_id+1} (PM2.5={values[0]:6.2f}, NO2={values[1]:6.2f})\")\n",
    "\n",
    "# Visualize iterations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Show first 4 iterations (or all if fewer)\n",
    "iterations_to_show = min(4, len(kmeans_p4.iteration_history))\n",
    "\n",
    "for iter_idx in range(iterations_to_show):\n",
    "    ax = axes[iter_idx]\n",
    "    \n",
    "    # Get centroids for this iteration\n",
    "    current_centroids = kmeans_p4.iteration_history[iter_idx]\n",
    "    \n",
    "    # Get assignments for this iteration (if available)\n",
    "    if iter_idx < len(kmeans_p4.assignment_history):\n",
    "        current_assignments = kmeans_p4.assignment_history[iter_idx]\n",
    "    else:\n",
    "        current_assignments = [0] * len(clustering_data_p4)  # Default assignment\n",
    "    \n",
    "    # Plot data points colored by cluster\n",
    "    colors = ['red', 'blue', 'green', 'orange']\n",
    "    for i in range(len(current_centroids)):\n",
    "        cluster_cities = [city for city, cluster in zip(city_names_p4, current_assignments) if cluster == i]\n",
    "        cluster_data = [city_averages_p4[city] for city in cluster_cities]\n",
    "        \n",
    "        if cluster_data:\n",
    "            pm25_values = [point[0] for point in cluster_data]\n",
    "            no2_values = [point[1] for point in cluster_data]\n",
    "            ax.scatter(pm25_values, no2_values, c=colors[i], label=f'Cluster {i+1}', s=100, alpha=0.7)\n",
    "    \n",
    "    # Plot centroids\n",
    "    for i, centroid in enumerate(current_centroids):\n",
    "        ax.scatter(centroid[0], centroid[1], c='black', marker='X', s=200, \n",
    "                   edgecolors=colors[i], linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('PM2.5 (μg/m³)')\n",
    "    ax.set_ylabel('NO2 (μg/m³)')\n",
    "    ax.set_title(f'Iteration {iter_idx + 1}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Presenter 4: K-Means Iterations - Centroid Movement (PM2.5 vs NO2)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Conclusion from Clustered Graph:\")\n",
    "print(\"Clusters capture pollutant-compositional diversity among cities. Iterative centroid\")\n",
    "print(\"updates provide insight into how clustering converges on meaningful groupings\")\n",
    "print(\"in multi-dimensional space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143ae1a",
   "metadata": {},
   "source": [
    "## Section 6: Presenter 5 - Multi-Feature Three-Pollutant Clustering\n",
    "\n",
    "**Topic**: Clustering of 7 cities using PM2.5, PM10, and NO2  \n",
    "**Dataset Focus**: Multi-pollutant averages from 7 cities in the dataset  \n",
    "**Method**: Manual K-Means with K=2 clusters over three features using multi-dimensional Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presenter 5: Multi-Feature Three-Pollutant Clustering\n",
    "\n",
    "# Select 7 cities for analysis\n",
    "selected_cities_p5 = ['Bangkok', 'Istanbul', 'Mumbai', 'Paris', 'Tokyo', 'New York', 'London']\n",
    "\n",
    "# Get average PM2.5, PM10, and NO2 values for these cities\n",
    "pollutants_p5 = ['PM2.5', 'PM10', 'NO2']\n",
    "city_averages_p5 = get_city_averages(air_quality_data, selected_cities_p5, pollutants_p5)\n",
    "\n",
    "print(\"Presenter 5: City averages for PM2.5, PM10, and NO2\")\n",
    "print(\"=\" * 60)\n",
    "for city, values in city_averages_p5.items():\n",
    "    print(f\"{city:15}: PM2.5={values[0]:6.2f}, PM10={values[1]:6.2f}, NO2={values[2]:6.2f}\")\n",
    "\n",
    "# Prepare data for clustering\n",
    "clustering_data_p5 = list(city_averages_p5.values())\n",
    "city_names_p5 = list(city_averages_p5.keys())\n",
    "\n",
    "print(f\"\\nClustering data shape: {len(clustering_data_p5)} cities × {len(pollutants_p5)} features\")\n",
    "\n",
    "# Perform K-Means clustering with K=2\n",
    "kmeans_p5 = ManualKMeans(k=2, random_state=42)\n",
    "kmeans_p5.fit(clustering_data_p5)\n",
    "\n",
    "print(\"\\nPresenter 5: K-Means Clustering Results (K=2)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display final centroids\n",
    "print(\"Final Centroids (Multi-Pollutant Profiles):\")\n",
    "for i, centroid in enumerate(kmeans_p5.centroids):\n",
    "    print(f\"Cluster {i+1}: PM2.5={centroid[0]:6.2f}, PM10={centroid[1]:6.2f}, NO2={centroid[2]:6.2f}\")\n",
    "\n",
    "print(\"\\nCluster Results - Clear Groups Based on Combined Pollutant Profiles:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Group cities by cluster\n",
    "clusters_dict_p5 = defaultdict(list)\n",
    "for city, cluster_id in zip(city_names_p5, kmeans_p5.cluster_assignments):\n",
    "    values = city_averages_p5[city]\n",
    "    clusters_dict_p5[cluster_id].append((city, values))\n",
    "\n",
    "# Display each cluster with comprehensive analysis\n",
    "cluster_labels = ['Cleaner Cities', 'More Polluted Cities']\n",
    "\n",
    "for cluster_id in range(kmeans_p5.k):\n",
    "    centroid = kmeans_p5.centroids[cluster_id]\n",
    "    print(f\"\\n🌍 {cluster_labels[cluster_id].upper()} (Cluster {cluster_id+1}):\")\n",
    "    print(f\"   Centroid Profile: PM2.5={centroid[0]:.2f}, PM10={centroid[1]:.2f}, NO2={centroid[2]:.2f}\")\n",
    "    print(\"   Cities in this cluster:\")\n",
    "    \n",
    "    for city, values in sorted(clusters_dict_p5[cluster_id], key=lambda x: sum(x[1])):\n",
    "        total_pollution = sum(values)\n",
    "        print(f\"   • {city:15}: PM2.5={values[0]:6.2f}, PM10={values[1]:6.2f}, NO2={values[2]:6.2f} (Total: {total_pollution:6.2f})\")\n",
    "\n",
    "# Calculate cluster statistics\n",
    "print(\"\\n📊 Cluster Statistics:\")\n",
    "for cluster_id in range(kmeans_p5.k):\n",
    "    cluster_cities = clusters_dict_p5[cluster_id]\n",
    "    if cluster_cities:\n",
    "        pm25_avg = sum(values[0] for _, values in cluster_cities) / len(cluster_cities)\n",
    "        pm10_avg = sum(values[1] for _, values in cluster_cities) / len(cluster_cities)\n",
    "        no2_avg = sum(values[2] for _, values in cluster_cities) / len(cluster_cities)\n",
    "        \n",
    "        print(f\"   {cluster_labels[cluster_id]}:\")\n",
    "        print(f\"     Average PM2.5: {pm25_avg:.2f} μg/m³\")\n",
    "        print(f\"     Average PM10:  {pm10_avg:.2f} μg/m³\")\n",
    "        print(f\"     Average NO2:   {no2_avg:.2f} μg/m³\")\n",
    "        print(f\"     Total cities:  {len(cluster_cities)}\")\n",
    "\n",
    "print(\"\\n📊 Conclusion from Multi-Pollutant Clustering:\")\n",
    "print(\"Multi-pollutant analysis yields comprehensive pollution profiles, better capturing\")\n",
    "print(\"complexity of air quality. Clustering distinguishes cleaner vs. more polluted groups\")\n",
    "print(\"for multilayered health and environmental assessments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1ee2c",
   "metadata": {},
   "source": [
    "## Section 7: Results Comparison and Analysis\n",
    "\n",
    "Let's compare all the clustering results and analyze the effectiveness of different feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a568c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and Overall Conclusions\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n🎯 PRESENTER CONTRIBUTIONS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n1️⃣ PRESENTER 1 - Simple 2D Clustering (PM2.5 & PM10)\")\n",
    "print(f\"   • Method: K=2 clusters on {len(city_names)} cities\")\n",
    "print(f\"   • Features: 2D (PM2.5, PM10)\")\n",
    "print(f\"   • Result: Clear separation into high/low pollution groups\")\n",
    "print(f\"   • Insight: Basic pollution distinction with just two features\")\n",
    "\n",
    "print(\"\\n2️⃣ PRESENTER 2 - Country-Level AQI Clustering\")\n",
    "print(f\"   • Method: K=3 clusters on {len(country_names_p2)} countries\") \n",
    "print(f\"   • Features: 1D (AQI)\")\n",
    "print(f\"   • Result: Low/Medium/High pollution country categories\")\n",
    "print(f\"   • Insight: National-level policy targeting capabilities\")\n",
    "\n",
    "print(\"\\n3️⃣ PRESENTER 3 - City-Level AQI Clustering\")\n",
    "print(f\"   • Method: K=3 clusters on {len(city_names_p3)} cities\")\n",
    "print(f\"   • Features: 1D (AQI)\")\n",
    "print(f\"   • Result: Urban pollution management groupings\")\n",
    "print(f\"   • Insight: Local pollution discrepancy identification\")\n",
    "\n",
    "print(\"\\n4️⃣ PRESENTER 4 - Two-Pollutant City Clustering (PM2.5 & NO2)\")\n",
    "print(f\"   • Method: K=3 clusters on {len(city_names_p4)} cities with iterations\")\n",
    "print(f\"   • Features: 2D (PM2.5, NO2)\")\n",
    "print(f\"   • Result: Pollutant-compositional diversity capture\")\n",
    "print(f\"   • Insight: Convergence visualization in multi-dimensional space\")\n",
    "\n",
    "print(\"\\n5️⃣ PRESENTER 5 - Multi-Feature Three-Pollutant Clustering\")\n",
    "print(f\"   • Method: K=2 clusters on {len(city_names_p5)} cities\")\n",
    "print(f\"   • Features: 3D (PM2.5, PM10, NO2)\")\n",
    "print(f\"   • Result: Comprehensive pollution profiles\")\n",
    "print(f\"   • Insight: Complex air quality patterns for health assessments\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📈 ANALYSIS PROGRESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "progression_data = [\n",
    "    (\"Presenter 1\", \"2D\", \"PM2.5, PM10\", 2, \"Visual separation\"),\n",
    "    (\"Presenter 2\", \"1D\", \"AQI\", 3, \"Policy targeting\"),\n",
    "    (\"Presenter 3\", \"1D\", \"AQI\", 3, \"Urban management\"),\n",
    "    (\"Presenter 4\", \"2D\", \"PM2.5, NO2\", 3, \"Iterative convergence\"),\n",
    "    (\"Presenter 5\", \"3D\", \"PM2.5, PM10, NO2\", 2, \"Comprehensive profiles\")\n",
    "]\n",
    "\n",
    "print(f\"{'Presenter':<12} {'Dims':<4} {'Features':<18} {'K':<3} {'Key Insight'}\")\n",
    "print(\"-\" * 70)\n",
    "for presenter, dims, features, k, insight in progression_data:\n",
    "    print(f\"{presenter:<12} {dims:<4} {features:<18} {k:<3} {insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 OVERALL CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✅ KEY FINDINGS:\")\n",
    "print(\"   • Multi-pollutant K-Means clustering reveals meaningful air quality patterns\")\n",
    "print(\"   • Progression from simple to complex features enhances analytical depth\")\n",
    "print(\"   • Different scales (city vs country) provide complementary insights\")\n",
    "print(\"   • Manual implementation demonstrates algorithmic understanding\")\n",
    "print(\"   • Clustering supports evidence-based environmental decision making\")\n",
    "\n",
    "print(\"\\n🌍 PRACTICAL APPLICATIONS:\")\n",
    "print(\"   • Health Risk Assessment: Identify high-risk pollution zones\")\n",
    "print(\"   • Resource Allocation: Target interventions based on cluster profiles\")\n",
    "print(\"   • Policy Development: National vs local pollution management strategies\")\n",
    "print(\"   • Environmental Monitoring: Systematic pollution pattern recognition\")\n",
    "print(\"   • Urban Planning: Inform sustainable city development\")\n",
    "\n",
    "print(\"\\n🔮 FUTURE SCOPE:\")\n",
    "print(\"   • Temporal Analysis: Incorporate seasonal/yearly pollution trends\")\n",
    "print(\"   • Socio-Economic Integration: Add demographic and economic indicators\")\n",
    "print(\"   • Weather Correlation: Include meteorological factors\")\n",
    "print(\"   • Advanced Clustering: Compare with DBSCAN, hierarchical methods\")\n",
    "print(\"   • Real-time Monitoring: Dynamic clustering for live air quality data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Thank you for following this comprehensive multi-pollutant clustering analysis!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
